{"cells":[{"cell_type":"markdown","metadata":{},"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n","\n","\u003ch1 align=\"center\"\u003e\u003cfont size=\"5\"\u003eFinal Project: Classification with Python\u003c/font\u003e\u003c/h1\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eTable of Contents\u003c/h2\u003e\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","    \u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://#Section_1\"\u003eInstructions\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://#Section_2\"\u003eAbout the Data\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://#Section_3\"\u003eImporting Data \u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://#Section_4\"\u003eData Preprocessing\u003c/a\u003e \u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://#Section_5\"\u003eTransforming Categorical Variables \u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://#Section_6\"\u003eTrain and Test Data Split \u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://#Section_7\"\u003eTrain Linear Regression, KNN, Decision Tree, Logistic Regression, and SVM models and return their appropriate accuracy scores\u003c/a\u003e\u003c/li\u003e\n","\u003c/a\u003e\u003c/li\u003e\n","\u003c/div\u003e\n","\u003cp\u003eEstimated Time Needed: \u003cstrong\u003e180 min\u003c/strong\u003e\u003c/p\u003e\n","\u003c/div\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["# Instructions\n"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook, you will  practice all the classification algorithms that we learned in this course.\n","\n","After completing this notebook, you will need to upload it to the \"Submit Your Work and Review Your Peers\" section of the Final Project module.\n","\n","Below, is where we are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course.\n","\n","We will use some of the algorithms taught in the course, specifically:\n","\n","1.  Linear Regression\n","2.  KNN\n","3.  Decision Trees\n","4.  Logistic Regression\n","5.  SVM\n","\n","We will evaluate our models using:\n","\n","1.  Accuracy Score\n","2.  Jaccard Index\n","3.  F1-Score\n","4.  LogLoss\n","5.  Mean Absolute Error\n","6.  Mean Squared Error\n","7.  R2-Score\n","\n","Finally, you will use your models to generate the report displaying the accuracy scores.\n"]},{"cell_type":"markdown","metadata":{},"source":["# About The Dataset\n"]},{"cell_type":"markdown","metadata":{},"source":["The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n","\n","The dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n","\n","| Field         | Description                                           | Unit            | Type   |\n","| ------------- | ----------------------------------------------------- | --------------- | ------ |\n","| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n","| Location      | Location of the Observation                           | Location        | object |\n","| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n","| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n","| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n","| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n","| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n","| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n","| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n","| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n","| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n","| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n","| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n","| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n","| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n","| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n","| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n","| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n","| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n","| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n","| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n","| RainToday     | If there was rain today                               | Yes/No          | object |\n","| RISK_MM       | Amount of rain tomorrow                               | Millimeters     | float  |\n","| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n","\n","Column definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Import the required libraries**\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Surpress warnings:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LinearRegression\n","from sklearn import preprocessing\n","import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import svm\n","from sklearn.metrics import jaccard_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import log_loss\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","import sklearn.metrics as metrics"]},{"cell_type":"markdown","metadata":{},"source":["### Importing the Dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv')\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Data Preprocessing\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Transforming Categorical Variables\n"]},{"cell_type":"markdown","metadata":{},"source":["First, we need to convert categorical variables to binary variables. We will use pandas `get_dummies()` method for this.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])"]},{"cell_type":"markdown","metadata":{},"source":["Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Training Data and Test Data\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, we set our 'features' or x values and our Y or target variable.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_sydney_processed.drop('Date',axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_sydney_processed = df_sydney_processed.astype(float)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\n","Y = df_sydney_processed['RainTomorrow']"]},{"cell_type":"markdown","metadata":{},"source":["### Linear Regression\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LinearReg = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LinearRegression_MAE = \n","LinearRegression_MSE = \n","LinearRegression_R2 = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Report = "]},{"cell_type":"markdown","metadata":{},"source":["### KNN\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["KNN = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q8) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["KNN_Accuracy_Score = \n","KNN_JaccardIndex = \n","KNN_F1_Score = "]},{"cell_type":"markdown","metadata":{},"source":["### Decision Tree\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Tree = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Tree_Accuracy_Score = \n","Tree_JaccardIndex = \n","Tree_F1_Score = "]},{"cell_type":"markdown","metadata":{},"source":["### Logistic Regression\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LR = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q14) Now, use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q15) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LR_Accuracy_Score = \n","LR_JaccardIndex = \n","LR_F1_Score = \n","LR_Log_Loss = "]},{"cell_type":"markdown","metadata":{},"source":["### SVM\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["SVM = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = "]},{"cell_type":"markdown","metadata":{},"source":["#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["SVM_Accuracy_Score = \n","SVM_JaccardIndex = \n","SVM_F1_Score = "]},{"cell_type":"markdown","metadata":{},"source":["### Report\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n","\n","\\*LogLoss is only for Logistic Regression Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Enter Your Code, Execute and take the Screenshot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Report = "]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2 id=\"Section_5\"\u003e  How to submit \u003c/h2\u003e\n","\n","\u003cp\u003eOnce you complete your notebook you will have to share it. You can download the notebook by navigating to \"File\" and clicking on \"Download\" button.\n","\n","\u003cp\u003eThis will save the (.ipynb) file on your computer. Once saved, you can upload this file in the \"My Submission\" tab, of the \"Peer-graded Assignment\" section.  \n"]},{"cell_type":"markdown","metadata":{},"source":["\u003ch2\u003eAbout the Authors:\u003c/h2\u003e \n","\n","\u003ca href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\"\u003eJoseph Santarcangelo\u003c/a\u003e has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n","\n","### Other Contributors\n","\n","\u003ca href=\"https://www.linkedin.com/in/birlahimanshu/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\"\u003eHimanshu Birla\u003c/a\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By    | Change Description          |\n","| ----------------- | ------- | ------------- | --------------------------- |\n","| 2020-08-27        | 1.0     | Malika Singla | Added lab to GitLab         |\n","| 2022-06-22        | 2.0     | Lana K.       | Deleted GridSearch and Mock |\n","| \u003chr\u003e              |         |               |                             |\n","\n","## \u003ch3 align=\"center\"\u003e Â© IBM Corporation 2020. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}